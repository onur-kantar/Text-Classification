{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string,unicodedata\n",
    "from keras.preprocessing import text, sequence\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from string import punctuation\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Embedding,LSTM,Dropout\n",
    "import tensorflow as tf\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>durum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dun Turkcelle tepkilerimizden sonra bugün Turk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>girmezmiyim.. Turkcell kartim bile var.. Yarin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tam tünelden gecerken 3g cekiyordu :D türkcell...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>turkcell superonline fiber internet veya ADSL ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bence Gnçtrkcll Ark Winterfest 2012'de 1.olur ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>turkcell sana kıyak geçiyor :D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Turkcelle bağlan hayata diyorum ;)))</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kimse takmıyo beni yaaaaa, turkcell bana mesaj...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bu Turkcell pusula uygulaması iPhone kullanıcı...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>o zaman sorun yok bende turkcell için iyi bir ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  durum\n",
       "0  dun Turkcelle tepkilerimizden sonra bugün Turk...      1\n",
       "1  girmezmiyim.. Turkcell kartim bile var.. Yarin...      1\n",
       "2  tam tünelden gecerken 3g cekiyordu :D türkcell...      1\n",
       "3  turkcell superonline fiber internet veya ADSL ...      1\n",
       "4  bence Gnçtrkcll Ark Winterfest 2012'de 1.olur ...      1\n",
       "5                     turkcell sana kıyak geçiyor :D      1\n",
       "6               Turkcelle bağlan hayata diyorum ;)))      1\n",
       "7  Kimse takmıyo beni yaaaaa, turkcell bana mesaj...      1\n",
       "8  Bu Turkcell pusula uygulaması iPhone kullanıcı...      1\n",
       "9  o zaman sorun yok bende turkcell için iyi bir ...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"3000tweet/3000tweet.csv\", sep=';',encoding=\"utf8\")\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet    1\n",
       "durum    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() # Checking for NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet    0\n",
       "durum    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() # Checking for NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('turkish'))\n",
    "punctuation = list(string.punctuation)\n",
    "stop.update(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuations and numbers\n",
    "def remove_punctuations(text):\n",
    "    return re.sub('[^\\w\\s]', ' ', text)\n",
    "\n",
    "#Single character removal\n",
    "def remove_single_character(text):\n",
    "    return re.sub(r\"\\b[\\w\\s]\\b\", ' ',text)\n",
    "\n",
    "#Removing multiple spaces\n",
    "def removing_multiple_spaces(text):\n",
    "    return re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "# Removing URL's\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "#Removing the stopwords from text\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop:\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)\n",
    "\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = remove_punctuations(text)\n",
    "    text = remove_single_character(text)\n",
    "    text = removing_multiple_spaces(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text.lower()\n",
    " \n",
    "#number silersek doğruluk değeri yükselir mi? dene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet']=df['tweet'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>durum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dun turkcelle tepkilerimizden sonra bugün turk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>girmezmiyim turkcell kartim bile var yarindan ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tam tünelden gecerken 3g cekiyordu türkcell in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>turkcell superonline fiber internet adsl sabit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bence gnçtrkcll ark winterfest 2012 olur gelir</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>turkcell sana kıyak geçiyor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>turkcelle bağlan hayata diyorum</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kimse takmıyo beni yaaaaa turkcell bana mesaj ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>turkcell pusula uygulaması iphone kullanıcılar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>zaman sorun yok bende turkcell iyi bir tarife ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  durum\n",
       "0  dun turkcelle tepkilerimizden sonra bugün turk...      1\n",
       "1  girmezmiyim turkcell kartim bile var yarindan ...      1\n",
       "2  tam tünelden gecerken 3g cekiyordu türkcell in...      1\n",
       "3  turkcell superonline fiber internet adsl sabit...      1\n",
       "4     bence gnçtrkcll ark winterfest 2012 olur gelir      1\n",
       "5                        turkcell sana kıyak geçiyor      1\n",
       "6                    turkcelle bağlan hayata diyorum      1\n",
       "7  kimse takmıyo beni yaaaaa turkcell bana mesaj ...      1\n",
       "8  turkcell pusula uygulaması iphone kullanıcılar...      1\n",
       "9  zaman sorun yok bende turkcell iyi bir tarife ...      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for i in df.tweet.values:\n",
    "    l = []\n",
    "    for j in i.split():\n",
    "        l.extend(i.split())\n",
    "        break\n",
    "    words.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "#Dimension of vectors we are generating\n",
    "EMBEDDING_DIM = 500\n",
    "\n",
    "#Creating Word Vectors by Word2Vec Method (takes time...)\n",
    "w2v_model = gensim.models.Word2Vec(sentences = words , size=EMBEDDING_DIM , window = 3 , min_count = 1,workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12001"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(j) for j in words], bins = 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(words)\n",
    "tokenized_train = tokenizer.texts_to_sequences(words)\n",
    "x = sequence.pad_sequences(tokenized_train, maxlen = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_matrix(model, vocab):\n",
    "    # total vocabulary size plus 0 for unknown words\n",
    "    vocab_size = len(vocab) + 1\n",
    "    # define weight matrix dimensions with all 0\n",
    "    weight_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "    # step vocab, store vectors using the Tokenizer's integer mapping\n",
    "    for word, i in vocab.items():\n",
    "        weight_matrix[i] = model[word]\n",
    "    return weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "embedding_vectors = get_weight_matrix(w2v_model, tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Neural Network\n",
    "model = Sequential()\n",
    "#Non-trainable embeddidng layer\n",
    "model.add(Embedding(vocab_size, output_dim=EMBEDDING_DIM, weights=[embedding_vectors], input_length=75, trainable=True))\n",
    "#LSTM \n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "del embedding_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 75, 500)           6001000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               322048    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 6,323,177\n",
      "Trainable params: 6,323,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, df.durum , test_size = 0.3 , random_state = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2099 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "2099/2099 [==============================] - 8s 4ms/step - loss: -3.0888 - acc: 0.2349 - val_loss: -9.1268 - val_acc: 0.2656\n",
      "Epoch 2/5\n",
      "2099/2099 [==============================] - 7s 3ms/step - loss: -13.0992 - acc: 0.2463 - val_loss: -15.5533 - val_acc: 0.2656\n",
      "Epoch 3/5\n",
      "2099/2099 [==============================] - 7s 3ms/step - loss: -17.8895 - acc: 0.2463 - val_loss: -18.7653 - val_acc: 0.2656\n",
      "Epoch 4/5\n",
      "2099/2099 [==============================] - 7s 3ms/step - loss: -20.9350 - acc: 0.2463 - val_loss: -21.4298 - val_acc: 0.2656\n",
      "Epoch 5/5\n",
      "2099/2099 [==============================] - 7s 4ms/step - loss: -23.7257 - acc: 0.2463 - val_loss: -23.8999 - val_acc: 0.2656\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size = 128 , validation_data = (x_test,y_test) , epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
